{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_LENGHT = 14\n",
    "OUTPUT_LENGHT = INPUT_LENGHT\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(INPUT_LENGHT, 50)  # Input layer with 10 features and 50 outputs\n",
    "        self.relu = nn.ReLU()            # ReLU activation function\n",
    "        self.layer2 = nn.Linear(50, 50)\n",
    "\n",
    "        self.layer3 = nn.Linear(50, OUTPUT_LENGHT)   # Output layer with 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Using SGD optimizer\n",
    "loss_function = nn.MSELoss()  # Mean Squared Error Loss for regression tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: ' ', 27: '0', 28: '1', 29: '2', 30: '3', 31: '4', 32: '5', 33: '6', 34: '7', 35: '8', 36: '9'}\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, ' ': 0, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chr_to_index = {chr(i): i + 1 - ord('a') for i in range( ord('a'), ord('z')+1 )}\n",
    "index_to_chr = {i + 1- ord('a'): chr(i) for i in range( ord('a'), ord('z')+1 )}\n",
    "chr_to_index[' '] = 0\n",
    "index_to_chr[0] = ' '\n",
    "for i in range(10):\n",
    "    chr_to_index[str(i)] = i + 27\n",
    "    index_to_chr[i + 27] = str(i)\n",
    "\n",
    "print(index_to_chr)\n",
    "print(chr_to_index)\n",
    "# chr_to_index type must be long\n",
    "#chr_to_index = {k: torch.tensor(v, dtype=torch.long) for k, v in chr_to_index.items()}\n",
    "#index_to_chr = {torch.tensor(k, dtype=torch.long): v for k, v in index_to_chr.items()}\n",
    "\n",
    "\n",
    "def str_to_tensor(word):\n",
    "    tensor = torch.zeros(INPUT_LENGHT)\n",
    "    for c, char in enumerate(word):\n",
    "        if c >= INPUT_LENGHT:\n",
    "            break\n",
    "        if char.lower() not in chr_to_index:\n",
    "            value = 0\n",
    "        else:\n",
    "            value = (chr_to_index[char.lower()] + 0.5) / 36\n",
    "        #print(value)\n",
    "        tensor[c] = value\n",
    "    return tensor\n",
    "\n",
    "def tensor_to_str(tensor):\n",
    "    s = ''\n",
    "    for i in tensor:\n",
    "        index = int(i.item() * 36)\n",
    "        index = max(0, min(35, index))\n",
    "        s += index_to_chr[index]\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1806, 0.4306, 0.5139, 0.5694, 0.5972, 0.4028, 0.0417, 0.0139, 0.3750,\n",
      "         0.0417, 0.2917, 0.4306, 0.5139, 0.0000],\n",
      "        [0.0972, 0.4306, 0.1250, 0.1528, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2639, 0.4028, 0.0417, 0.3194, 0.2639, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0417, 0.7083, 0.3750, 0.1528, 0.5139, 0.2639, 0.0972, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4583, 0.7083, 0.5694, 0.2361, 0.4306, 0.4028, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2639, 0.4028, 0.1250, 0.2639, 0.0972, 0.1528, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3194, 0.0417, 0.5139, 0.2639, 0.3750, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5139, 0.1528, 0.3750, 0.7083, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0972, 0.0000, 0.5417, 0.0417, 0.5139, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2361, 0.0417, 0.5139, 0.5139, 0.7083, 0.0139, 0.4583, 0.4306, 0.5694,\n",
      "         0.5694, 0.1528, 0.5139, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "inputs = ['fortuna major', 'code', 'inaki', 'aymeric', 'python', 'indice','karim','remy','c√©sar','harry potter','cesar'] \n",
    "right_output = ['code 8135', 'ou est il', 'quel bg', 'un monstre', 'pip install',\"pas si simple\",'le crack','lpb','asiatique','en effet','asiatique'] \n",
    "\n",
    "\n",
    "inputs = [str_to_tensor(i) for i in inputs]\n",
    "right_output = [str_to_tensor(i) for i in right_output]\n",
    "#print(inputs)\n",
    "# combine the inputs into a single tensor\n",
    "inputs = torch.stack(inputs)\n",
    "right_output = torch.stack(right_output)\n",
    "print(inputs)\n",
    "\n",
    "# use torch random inputs\n",
    "#inputs = torch.randn(10, 14)\n",
    "#right_output = torch.randn(10, 14)\n",
    "#print(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss: 6.165303784655407e-05\n",
      "Epoch 2000, Loss: 5.9159487136639655e-05\n",
      "Epoch 3000, Loss: 5.676308137481101e-05\n",
      "Epoch 4000, Loss: 5.4463253036374226e-05\n",
      "Epoch 5000, Loss: 5.225756103754975e-05\n",
      "Epoch 6000, Loss: 5.013749250792898e-05\n",
      "Epoch 7000, Loss: 4.810523023479618e-05\n",
      "Epoch 8000, Loss: 4.615537545760162e-05\n",
      "Epoch 9000, Loss: 4.428533429745585e-05\n",
      "Epoch 10000, Loss: 4.248811455909163e-05\n",
      "Epoch 11000, Loss: 4.076309051015414e-05\n",
      "Epoch 12000, Loss: 3.910726445610635e-05\n",
      "Epoch 13000, Loss: 3.751938493223861e-05\n",
      "Epoch 14000, Loss: 3.599771298468113e-05\n",
      "Epoch 15000, Loss: 3.453675890341401e-05\n",
      "Epoch 16000, Loss: 3.313626802992076e-05\n",
      "Epoch 17000, Loss: 3.1796782423043624e-05\n",
      "Epoch 18000, Loss: 3.0509625503327698e-05\n",
      "Epoch 19000, Loss: 2.927388050011359e-05\n",
      "Epoch 20000, Loss: 2.8091675631003454e-05\n",
      "Epoch 21000, Loss: 2.6957870431942865e-05\n",
      "Epoch 22000, Loss: 2.5871448087855242e-05\n",
      "Epoch 23000, Loss: 2.483075331838336e-05\n",
      "Epoch 24000, Loss: 2.383394712524023e-05\n",
      "Epoch 25000, Loss: 2.287689312652219e-05\n",
      "Epoch 26000, Loss: 2.196080458816141e-05\n",
      "Epoch 27000, Loss: 2.1083513274788857e-05\n",
      "Epoch 28000, Loss: 2.024236528086476e-05\n",
      "Epoch 29000, Loss: 1.9434661226114258e-05\n",
      "Epoch 30000, Loss: 1.866019010776654e-05\n",
      "Epoch 31000, Loss: 1.7918544472195208e-05\n",
      "Epoch 32000, Loss: 1.7207921700901352e-05\n",
      "Epoch 33000, Loss: 1.652692117204424e-05\n",
      "Epoch 34000, Loss: 1.587915903655812e-05\n",
      "Epoch 35000, Loss: 1.5262690794770606e-05\n",
      "Epoch 36000, Loss: 1.4671500139229465e-05\n",
      "Epoch 37000, Loss: 1.410534605383873e-05\n",
      "Epoch 38000, Loss: 1.3562834283220582e-05\n",
      "Epoch 39000, Loss: 1.3043214494246058e-05\n",
      "Epoch 40000, Loss: 1.2544160199468024e-05\n",
      "Epoch 41000, Loss: 1.206624074256979e-05\n",
      "Epoch 42000, Loss: 1.1607992746576201e-05\n",
      "Epoch 43000, Loss: 1.116778003051877e-05\n",
      "Epoch 44000, Loss: 1.0744676728791092e-05\n",
      "Epoch 45000, Loss: 1.0338671927456744e-05\n",
      "Epoch 46000, Loss: 9.948917977453675e-06\n",
      "Epoch 47000, Loss: 9.573931492923293e-06\n",
      "Epoch 48000, Loss: 9.213327757606748e-06\n",
      "Epoch 49000, Loss: 8.867135875334498e-06\n",
      "Epoch 50000, Loss: 8.534449989383575e-06\n",
      "Epoch 51000, Loss: 8.217514732677955e-06\n",
      "Epoch 52000, Loss: 7.913447916507721e-06\n",
      "Epoch 53000, Loss: 7.6208771133678965e-06\n",
      "Epoch 54000, Loss: 7.338962404901395e-06\n",
      "Epoch 55000, Loss: 7.067763817758532e-06\n",
      "Epoch 56000, Loss: 6.8075451054028235e-06\n",
      "Epoch 57000, Loss: 6.558766472153366e-06\n",
      "Epoch 58000, Loss: 6.3198617681337055e-06\n",
      "Epoch 59000, Loss: 6.0898360061401036e-06\n",
      "Epoch 60000, Loss: 5.868299012945499e-06\n",
      "Epoch 61000, Loss: 5.655333097820403e-06\n",
      "Epoch 62000, Loss: 5.450816388474777e-06\n",
      "Epoch 63000, Loss: 5.25449149790802e-06\n",
      "Epoch 64000, Loss: 5.065959157946054e-06\n",
      "Epoch 65000, Loss: 4.884726422460517e-06\n",
      "Epoch 66000, Loss: 4.710330813395558e-06\n",
      "Epoch 67000, Loss: 4.542499937087996e-06\n",
      "Epoch 68000, Loss: 4.381386133900378e-06\n",
      "Epoch 69000, Loss: 4.226096734782914e-06\n",
      "Epoch 70000, Loss: 4.07656352763297e-06\n",
      "Epoch 71000, Loss: 3.932312210963573e-06\n",
      "Epoch 72000, Loss: 3.793987843891955e-06\n",
      "Epoch 73000, Loss: 3.6621013350668363e-06\n",
      "Epoch 74000, Loss: 3.5359100820642198e-06\n",
      "Epoch 75000, Loss: 3.4144964047300164e-06\n",
      "Epoch 76000, Loss: 3.297184548500809e-06\n",
      "Epoch 77000, Loss: 3.1841414056543726e-06\n",
      "Epoch 78000, Loss: 3.0750766200071666e-06\n",
      "Epoch 79000, Loss: 2.969991328427568e-06\n",
      "Epoch 80000, Loss: 2.869023546736571e-06\n",
      "Epoch 81000, Loss: 2.771551862679189e-06\n",
      "Epoch 82000, Loss: 2.677881411727867e-06\n",
      "Epoch 83000, Loss: 2.58744012171519e-06\n",
      "Epoch 84000, Loss: 2.5004840153997065e-06\n",
      "Epoch 85000, Loss: 2.4166126877389615e-06\n",
      "Epoch 86000, Loss: 2.335644012418925e-06\n",
      "Epoch 87000, Loss: 2.2578233256353997e-06\n",
      "Epoch 88000, Loss: 2.182787966376054e-06\n",
      "Epoch 89000, Loss: 2.110426976287272e-06\n",
      "Epoch 90000, Loss: 2.0406246221682522e-06\n",
      "Epoch 91000, Loss: 1.9733649878617143e-06\n",
      "Epoch 92000, Loss: 1.908408876261092e-06\n",
      "Epoch 93000, Loss: 1.845935798883147e-06\n",
      "Epoch 94000, Loss: 1.785548874977394e-06\n",
      "Epoch 95000, Loss: 1.7273301864406676e-06\n",
      "Epoch 96000, Loss: 1.6712209571778658e-06\n",
      "Epoch 97000, Loss: 1.6171661627595313e-06\n",
      "Epoch 98000, Loss: 1.5648827229597373e-06\n",
      "Epoch 99000, Loss: 1.5144063354455284e-06\n",
      "Epoch 100000, Loss: 1.4657686051577912e-06\n",
      "Epoch 101000, Loss: 1.4190190995577723e-06\n",
      "Epoch 102000, Loss: 1.3743014051215141e-06\n",
      "Epoch 103000, Loss: 1.3310703934621415e-06\n",
      "Epoch 104000, Loss: 1.2893530083601945e-06\n",
      "Epoch 105000, Loss: 1.2490174867707537e-06\n",
      "Epoch 106000, Loss: 1.2101138509024167e-06\n",
      "Epoch 107000, Loss: 1.1725173862942029e-06\n",
      "Epoch 108000, Loss: 1.1360895086909295e-06\n",
      "Epoch 109000, Loss: 1.1009318541255197e-06\n",
      "Epoch 110000, Loss: 1.0669788252926082e-06\n",
      "Epoch 111000, Loss: 1.034325578075368e-06\n",
      "Epoch 112000, Loss: 1.0026607242252794e-06\n",
      "Epoch 113000, Loss: 9.719594800117193e-07\n",
      "Epoch 114000, Loss: 9.422003586223582e-07\n",
      "Epoch 115000, Loss: 9.13527571810846e-07\n",
      "Epoch 116000, Loss: 8.859532272254e-07\n",
      "Epoch 117000, Loss: 8.594840323894459e-07\n",
      "Epoch 118000, Loss: 8.337558483617613e-07\n",
      "Epoch 119000, Loss: 8.088470622169552e-07\n",
      "Epoch 120000, Loss: 7.847882557143748e-07\n",
      "Epoch 121000, Loss: 7.615178674313938e-07\n",
      "Epoch 122000, Loss: 7.390283371933037e-07\n",
      "Epoch 123000, Loss: 7.171866513999703e-07\n",
      "Epoch 124000, Loss: 6.960541441003443e-07\n",
      "Epoch 125000, Loss: 6.757040296179184e-07\n",
      "Epoch 126000, Loss: 6.560181304848811e-07\n",
      "Epoch 127000, Loss: 6.369024845298554e-07\n",
      "Epoch 128000, Loss: 6.18389492501592e-07\n",
      "Epoch 129000, Loss: 6.005070645187516e-07\n",
      "Epoch 130000, Loss: 5.832452529830334e-07\n",
      "Epoch 131000, Loss: 5.665415869771095e-07\n",
      "Epoch 132000, Loss: 5.503991928890173e-07\n",
      "Epoch 133000, Loss: 5.348164791030285e-07\n",
      "Epoch 134000, Loss: 5.197280756874534e-07\n",
      "Epoch 135000, Loss: 5.05163313846424e-07\n",
      "Epoch 136000, Loss: 4.911959763376217e-07\n",
      "Epoch 137000, Loss: 4.777992330673442e-07\n",
      "Epoch 138000, Loss: 4.6480315063490707e-07\n",
      "Epoch 139000, Loss: 4.5218226318866073e-07\n",
      "Epoch 140000, Loss: 4.3999341414746596e-07\n",
      "Epoch 141000, Loss: 4.2823288026738737e-07\n",
      "Epoch 142000, Loss: 4.1688372220960446e-07\n",
      "Epoch 143000, Loss: 4.0588940919406014e-07\n",
      "Epoch 144000, Loss: 3.952408746954461e-07\n",
      "Epoch 145000, Loss: 3.849360723506834e-07\n",
      "Epoch 146000, Loss: 3.7490073623303033e-07\n",
      "Epoch 147000, Loss: 3.6520600588119123e-07\n",
      "Epoch 148000, Loss: 3.559163701538637e-07\n",
      "Epoch 149000, Loss: 3.4691615269366594e-07\n",
      "Epoch 150000, Loss: 3.3818821520981146e-07\n",
      "Epoch 151000, Loss: 3.296950126241427e-07\n",
      "Epoch 152000, Loss: 3.214658477190824e-07\n",
      "Epoch 153000, Loss: 3.134495614176558e-07\n",
      "Epoch 154000, Loss: 3.0563450081899646e-07\n",
      "Epoch 155000, Loss: 2.980051760914648e-07\n",
      "Epoch 156000, Loss: 2.9055044592496415e-07\n",
      "Epoch 157000, Loss: 2.833091627962858e-07\n",
      "Epoch 158000, Loss: 2.7624426479633257e-07\n",
      "Epoch 159000, Loss: 2.6940776365336205e-07\n",
      "Epoch 160000, Loss: 2.627600395044283e-07\n",
      "Epoch 161000, Loss: 2.563000123245729e-07\n",
      "Epoch 162000, Loss: 2.5002981374200317e-07\n",
      "Epoch 163000, Loss: 2.43947852140991e-07\n",
      "Epoch 164000, Loss: 2.380669883450537e-07\n",
      "Epoch 165000, Loss: 2.3237002721998579e-07\n",
      "Epoch 166000, Loss: 2.2684915279569395e-07\n",
      "Epoch 167000, Loss: 2.214855783222447e-07\n",
      "Epoch 168000, Loss: 2.162603180977385e-07\n",
      "Epoch 169000, Loss: 2.112224848360711e-07\n",
      "Epoch 170000, Loss: 2.0630390906717366e-07\n",
      "Epoch 171000, Loss: 2.0151742319285404e-07\n",
      "Epoch 172000, Loss: 1.9684819108078955e-07\n",
      "Epoch 173000, Loss: 1.9230925829560874e-07\n",
      "Epoch 174000, Loss: 1.878740647498489e-07\n",
      "Epoch 175000, Loss: 1.8354337782966468e-07\n",
      "Epoch 176000, Loss: 1.7932551088506443e-07\n",
      "Epoch 177000, Loss: 1.7522688722237945e-07\n",
      "Epoch 178000, Loss: 1.712107575713162e-07\n",
      "Epoch 179000, Loss: 1.6730466256831278e-07\n",
      "Epoch 180000, Loss: 1.6351968668004702e-07\n",
      "Epoch 181000, Loss: 1.5983046353085228e-07\n",
      "Epoch 182000, Loss: 1.5622302385054354e-07\n",
      "Epoch 183000, Loss: 1.526998119061318e-07\n",
      "Epoch 184000, Loss: 1.4926295932582434e-07\n",
      "Epoch 185000, Loss: 1.4591938679586747e-07\n",
      "Epoch 186000, Loss: 1.4264971071042964e-07\n",
      "Epoch 187000, Loss: 1.3947841637218517e-07\n",
      "Epoch 188000, Loss: 1.3637983897751838e-07\n",
      "Epoch 189000, Loss: 1.3334062032299698e-07\n",
      "Epoch 190000, Loss: 1.3036405732691492e-07\n",
      "Epoch 191000, Loss: 1.2746644983963051e-07\n",
      "Epoch 192000, Loss: 1.2467164367535588e-07\n",
      "Epoch 193000, Loss: 1.2194247744901077e-07\n",
      "Epoch 194000, Loss: 1.1927662058042188e-07\n",
      "Epoch 195000, Loss: 1.1667138011262068e-07\n",
      "Epoch 196000, Loss: 1.141415495453657e-07\n",
      "Epoch 197000, Loss: 1.116788581612127e-07\n",
      "Epoch 198000, Loss: 1.0928927451914205e-07\n",
      "Epoch 199000, Loss: 1.0696061991666284e-07\n",
      "Epoch 200000, Loss: 1.0469737077301033e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50000):  # Loop over the dataset multiple times\n",
    "    optimizer.zero_grad()   # Zero the parameter gradients\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_function(outputs, right_output)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print statistics\n",
    "    if epoch % 1000 == 999:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: '', Output: code 8135     \n",
      "Input: '', Output: ou est il     \n",
      "Input: '', Output: quel bg       \n",
      "Input: '', Output: un monstre    \n",
      "Input: '', Output: pip install   \n",
      "Input: '', Output: pas si simple \n",
      "Input: '', Output: le crack      \n",
      "Input: '', Output: lpb           \n",
      "Input: '', Output: bonne voie    \n",
      "Input: '', Output: en effet      \n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "for inp in inputs:\n",
    "    #input = str_to_tensor('Bonjour')\n",
    "    output = model(inp)\n",
    "    str_output = tensor_to_str(output)\n",
    "    print(f\"Input: '', Output: {str_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     input_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnter a string: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_str \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m input_str \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py:1270\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py:1313\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_str = input('Enter a string: ')\n",
    "    if input_str == 'exit' or input_str == '':\n",
    "        break\n",
    "\n",
    "    input_tensor = str_to_tensor(input_str)\n",
    "    output = model(input_tensor)\n",
    "    str_output = tensor_to_str(output)\n",
    "    print(f\"Input: '{input_str}', Output: {str_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print('Model saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval() # set the model to evaluation mode\n",
    "print('Model loaded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
